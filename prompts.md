# prompts.md â€” ARU Academy

> This file documents the *two* prompts used to generate the ARU Academy eâ€‘learning system, how they relate to one another, how they were fed into an external AI editor Cursor), and practical instructions for reuse, iteration, and deployment.

---

## 1. Purpose

This repository was generated by prompting large AI systems. The goal of this `prompts.md` is to:  
â€¢ preserve the exact intent and structure of the prompts that produced the code;  
â€¢ explain how the prompts were chained (user prompt â†’ ChatGPT â†’ Cursor AI editor);  
â€¢ provide instructions for re-running, adapting, and deploying the system.

Use this file when you want to: recreate the project, iterate on features, or hand the prompts to another code generator/editor.

---

## 2. Prompt A â€” Original concept (user-supplied idea)

**Summary:** A high-level product brief describing the problem (uneven teaching quality) and proposing an eâ€‘learning system named **Aru Academy**. The system should allow verified instructors and students (department-scoped) to share resources, let students ask an AI tutor questions, and let the AI generate practice questions. The system must store resources per department and restrict access by role and department. Registration must verify acceptance and department; store name, email, password, department; track progress; secure authentication and authorization. The AI integration should be free/open-source friendly (example: Hugging Face). The code must be split into `public` and `backend` with modules and use free hosting/databases.

**Intent to the code generator:** produce a complete project (frontend + backend + DB + seed data + deployment instructions) that I can download and push to GitHub and then deploy.

**Key requirements from Prompt A (raw intent):**
- Name: **Aru Academy**
- Roles: students and instructors; department-limited access
- AI: allow asking questions + generate quizzes from studied topics
- Track student progress and quiz results
- Use free-tier or open-source AI APIs (Hugging Face suggested)
- Provide repo layout with `frontend/` and `backend/`

(Use this block as the conceptual brief if you want to re-run or refine features.)

---

## 3. Prompt B â€” Strict, production-ready spec (sent to ChatGPT as the developer)

**Summary:** A detailed, strict engineering prompt that specifies exact technologies, file structure, database models, endpoints, security measures, seed data, and deployment targets. This version is prescriptive and used to generate production-ready code.

**Main constraints (as given):**
- **Frontend:** vanilla HTML/CSS/JS (no frameworks)
- **Backend:** Python 3 + Flask
- **DB:** MySQL with SQLAlchemy + Alembic migrations
- **Auth:** JWT in httpOnly cookies + bcrypt hashing
- **AI:** Hugging Face Inference API via HTTP `requests`

**Features to implement fully (selected highlights):**
- Roles & Security: `student`, `instructor`, `admin`, approved users table, prevent self-elevation
- Department-based access (CS, EE, ME, Business)
- Resources & Courses with uploads stored under `/backend/storage/departments/<department>`
- AI Tutor endpoints: `/api/ai/ask` and `/api/ai/generate-questions` using `huggingface_provider.py`
- Quizzes: AI-generated, autograded, stored history
- Admin Dashboard: approve/deny users, import CSV, analytics
- Seed data and Alembic migrations
- Swagger API at `/api/docs`

**Project structure:** The prompt included a full tree (frontend, backend, many modules) and required deliverables (no placeholders, working migrations, seed, HF provider, ready to deploy on Vercel/Render/PlanetScale).

**Why two prompts?**
- Prompt A captures product vision and user needs.
- Prompt B translates that vision into a strict engineering contract the code generator must follow.

Use Prompt B when you need a deterministic, audit-friendly generation that you can hand to a CI/CD pipeline or another model editor.

---

## 4. How the prompts were *chained* (ChatGPT â†’ Cursor AI editor)

1. **User** provided Prompt A (high-level concept).
2. **Assistant (ChatGPT)** returned a robust, single power-prompt (a structured, actionable version of Prompt A) and then the user supplied Prompt B (the strict engineering spec).
3. **Assistant** (as a senior engineer) used Prompt B to generate the full repo and artifacts (code + migrations + seeds + docs).
4. The **final generation** step used the output from ChatGPT (the strict prompt and produced artifacts) as input to *Cursor AI editor** (or similar code editing/CI tool) to synthesize the full working codebase and produce downloadable files.

**Practical tip:** When passing prompts between systems, always include the full engineering constraints (stack, security, deployment) and an example of expected file/directory output. Attach the `schema.sql` / Alembic stamps so the editor can generate migrations deterministically.

---

## 5. `prompts.md` usage â€” how to re-run and iterate

### To re-run the generation pipeline (recommended workflow):
1. Open `prompts.md` and copy **Prompt B** into your editor or into ChatGPTCursor as the *system* or *developer* role prompt.
2. Add `seed.sql` + `alembic/versions/` (if you want identical DB migrations) or instruct the generator to produce Alembic migration scripts.
3. Provide environment specifics (HF token, DB host) via `.env` (do **not** paste secrets into prompts).
4. Run in small increments: request repo tree â†’ then file contents â†’ then unit tests â†’ then Docker compose and deploy scripts.

### When editing prompts:
- Keep constraints explicit (e.g., "use bcrypt", "JWT httpOnly cookie").  
- Ask for **one** change at a time (e.g., change auth from JWT to session) and run the generator to update only relevant modules.
- For heavy code generation, include sample inputs and expected outputs (example: a sample quiz JSON) to ensure models produce correct schemas.

---

## 6. How to feed the prompts intoCursor (or similar AI code editor)

1. Paste **Prompt B** as the primary instruction to theCursor editor. Use "code generation" or "full repo" mode if available.
2. Provide a separate message with `ALSO ADD` listing: `.env.example`, `docker-compose.yml`, `requirements.txt`, `alembic.ini`, and `README.md`.
3. Provide the desired license (MIT/Apache) and privacy notes about user data.
4. Attach `seed/seed.py` or `db/seed.sql` and request the editor create Alembic migration files that match the schema.
5. Run the editor's "synthesize files" job and review generated unit tests before running `docker-compose`.

**Important:** Never expose secrets to the AI; instead provide placeholders and inject secrets in your CI/CD later.

---

## 7. Deployment checklist (after generation)

1. Create a **Railway** (or Aiven) MySQL instance and import the schema.  
2. Provision a Render Web Service for the backend (or similar).  
3. Deploy the `public/` directory as a static site on Vercel.  
4. Populate environment variables (HF token, DB credentials, JWT secret) in Render/Vercel.  
5. Run migrations (Alembic upgrade head).  
6. Run the seed script (`python backend/seed/seed.py` or `alembic stamp head && python backend/seed/seed.py`).

---

## 8. Security & compliance notes

- Replace `HF_API_TOKEN` in `.env` with a secrets manager value.  
- Ensure backend only serves upload files from `/backend/storage` and uses signed URLs for public assets.  
- Rotate JWT and SECRET keys after deployment.  
- For production, enable HTTPS, set secure cookie flags, set `SameSite=Lax` or `Strict` as appropriate.

---

## 9. Extending prompts for future improvements

When you want to add features (examples below), extend Prompt B with a short bullet list and ask the editor to modify only the relevant modules.

- Add OAuth (Google, Microsoft) for campus SSO.  
- Add video streaming support with HLS and chunked uploads.  
- Add offline quiz support (PWA).  
- Add analytics export (CSV/BigQuery) for admin.

---

## 10. Appendices

### A â€” Example: Minimal invocation snippet for theCursor editor

```
SYSTEM: You are a senior full-stack engineer. Generate a complete repository implementing the following spec (copy/paste Prompt B below). Produce all files, Alembic migrations, seed scripts, tests, and a README with deployment steps.

USER: <paste Prompt B here>

INSTRUCTIONS: Output file by file. Start with backend/models, then backend/routes, then frontend pages, then Docker and CI. Keep code clean and tested.
```


**ARU Academy** - Empowering Education with AI Technology ðŸš€

